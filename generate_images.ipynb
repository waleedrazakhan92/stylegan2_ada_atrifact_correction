{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generate_images.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5f7f907d6a034beba8bd6adfdbe25452": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_31f4605bed1d49e793c18756c7de6ca3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d8af0105b456417188f5e5a18025c61e",
              "IPY_MODEL_9c9fd56551214232aa9516d4f84f11e0"
            ]
          }
        },
        "31f4605bed1d49e793c18756c7de6ca3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d8af0105b456417188f5e5a18025c61e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7cb7b3d052964988b0061a0307f1ba10",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Generating images: 20",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a244df1ebbec4ac18e066128dcfc0b2b"
          }
        },
        "9c9fd56551214232aa9516d4f84f11e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_03dcda9d2733478eb8990b3cdd649c1a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fcdab4163c9b4a92a4a529ea5e7df1ff"
          }
        },
        "7cb7b3d052964988b0061a0307f1ba10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a244df1ebbec4ac18e066128dcfc0b2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "03dcda9d2733478eb8990b3cdd649c1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fcdab4163c9b4a92a4a529ea5e7df1ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJdIQn20sAMq",
        "outputId": "46383f20-0ce6-49d8-b709-c52805f5d2bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jan 22 12:34:19 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clone the repository\n",
        "!git clone https://github.com/NVlabs/stylegan2-ada.git\n",
        "%cd stylegan2-ada\n",
        "\n",
        "# make the pretrained directory to put the model checkpoint in\n",
        "!mkdir pretrained\n",
        "%cd pretrained\n",
        "\n",
        "# download pretrained model\n",
        "!wget -O pretrained_ada_ffhq_1024.pkl http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-ffhq-config-f.pkl\n",
        "%cd ../"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD_wbX2SsMYL",
        "outputId": "0bff9dff-4e9e-45f7-dbbb-834c6aa73e70"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'stylegan2-ada'...\n",
            "remote: Enumerating objects: 74, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 74 (delta 0), reused 1 (delta 0), pack-reused 71\u001b[K\n",
            "Unpacking objects: 100% (74/74), done.\n",
            "/content/stylegan2-ada\n",
            "/content/stylegan2-ada/pretrained\n",
            "--2022-01-22 12:34:20--  http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-ffhq-config-f.pkl\n",
            "Resolving d36zk2xti64re0.cloudfront.net (d36zk2xti64re0.cloudfront.net)... 65.9.84.43, 65.9.84.122, 65.9.84.127, ...\n",
            "Connecting to d36zk2xti64re0.cloudfront.net (d36zk2xti64re0.cloudfront.net)|65.9.84.43|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 381673535 (364M) [application/x-www-form-urlencoded]\n",
            "Saving to: ‘pretrained_ada_ffhq_1024.pkl’\n",
            "\n",
            "pretrained_ada_ffhq 100%[===================>] 363.99M   190MB/s    in 1.9s    \n",
            "\n",
            "2022-01-22 12:34:22 (190 MB/s) - ‘pretrained_ada_ffhq_1024.pkl’ saved [381673535/381673535]\n",
            "\n",
            "/content/stylegan2-ada\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_dimensions = (1024, 1024)\n",
        "\n",
        "# model checkpoint for inference \n",
        "inference_ckpt='pretrained/pretrained_ada_ffhq_1024.pkl'\n",
        "\n",
        "#number of images to be generated\n",
        "grid_width=20 \n",
        "grid_height=1\n",
        "\n",
        "# folder in which images are stored\n",
        "inference_results = 'generated_images/' \n",
        "# folder in which ilatent codes are stored\n",
        "latent_results = 'generated_latents/'\n",
        "\n",
        "# truncation index. Set between 0.3-1.0\n",
        "trunc_idx = 0.7"
      ],
      "metadata": {
        "id": "ee5c5FDhsfGi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 1.x\n",
        " \n",
        "import sys\n",
        "sys.path.insert(1, 'stylegan2-ada/')\n",
        " \n",
        "# Download the model of choice\n",
        "import argparse\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "import re\n",
        "import sys\n",
        "from io import BytesIO\n",
        "import IPython.display\n",
        "import numpy as np\n",
        "from math import ceil\n",
        "from PIL import Image, ImageDraw\n",
        "import imageio\n",
        "import os\n",
        "import pickle\n",
        " \n",
        " \n",
        "Gs = None\n",
        "noise_vars = None\n",
        "# Useful utility functions...\n",
        " \n",
        "# Generates a list of images, based on a list of latent vectors (Z), and a list (or a single constant) of truncation_psi's.\n",
        "def generate_images_in_w_space(dlatents, truncation_psi):\n",
        "    Gs_kwargs = dnnlib.EasyDict()\n",
        "    Gs_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "    Gs_kwargs.randomize_noise = False\n",
        "    Gs_kwargs.truncation_psi = truncation_psi\n",
        "    dlatent_avg = Gs.get_var('dlatent_avg') # [component]\n",
        " \n",
        "    imgs = []\n",
        "    for row, dlatent in log_progress(enumerate(dlatents), name = \"Generating images\"):\n",
        "        #row_dlatents = (dlatent[np.newaxis] - dlatent_avg) * np.reshape(truncation_psi, [-1, 1, 1]) + dlatent_avg\n",
        "        dl = (dlatent-dlatent_avg)*truncation_psi   + dlatent_avg\n",
        "        row_images = Gs.components.synthesis.run(dlatent,  **Gs_kwargs)\n",
        "        imgs.append(PIL.Image.fromarray(row_images[0], 'RGB'))\n",
        "    return imgs       \n",
        " \n",
        "def generate_images(zs, truncation_psi):\n",
        "    Gs_kwargs = dnnlib.EasyDict()\n",
        "    Gs_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "    Gs_kwargs.randomize_noise = False\n",
        "    if not isinstance(truncation_psi, list):\n",
        "        truncation_psi = [truncation_psi] * len(zs)\n",
        "    \n",
        "    imgs = []\n",
        "    for z_idx, z in log_progress(enumerate(zs), size = len(zs), name = \"Generating images\"):\n",
        "        Gs_kwargs.truncation_psi = truncation_psi[z_idx]\n",
        "        noise_rnd = np.random.RandomState(1) # fix noise\n",
        "        tflib.set_vars({var: noise_rnd.randn(*var.shape.as_list()) for var in noise_vars}) # [height, width]\n",
        "        images = Gs.run(z, None, **Gs_kwargs) # [minibatch, height, width, channel]\n",
        "        imgs.append(PIL.Image.fromarray(images[0], 'RGB'))\n",
        " \n",
        "    return imgs\n",
        " \n",
        "def generate_zs_from_seeds(seeds):\n",
        "    zs = []\n",
        "    for seed_idx, seed in enumerate(seeds):\n",
        "        rnd = np.random.RandomState(seed)\n",
        "        z = rnd.randn(1, *Gs.input_shape[1:]) # [minibatch, component]\n",
        "        zs.append(z)\n",
        "    return zs\n",
        " \n",
        "# Generates a list of images, based on a list of seed for latent vectors (Z), and a list (or a single constant) of truncation_psi's.\n",
        "def generate_images_from_seeds(seeds, truncation_psi):\n",
        "    zs = generate_zs_from_seeds(seeds)\n",
        "    return generate_images(zs, truncation_psi), zs\n",
        " \n",
        "def saveImgs(imgs, location):\n",
        "  for idx, img in log_progress(enumerate(imgs), size = len(imgs), name=\"Saving images\"):\n",
        "    file = location+ str(idx) + \".png\"\n",
        "    img.save(file)\n",
        " \n",
        "def imshow(a, format='png', jpeg_fallback=True):\n",
        "  a = np.asarray(a, dtype=np.uint8)\n",
        "  str_file = BytesIO()\n",
        "  PIL.Image.fromarray(a).save(str_file, format)\n",
        "  im_data = str_file.getvalue()\n",
        "  try:\n",
        "    disp = IPython.display.display(IPython.display.Image(im_data))\n",
        "  except IOError:\n",
        "    if jpeg_fallback and format != 'jpeg':\n",
        "      print ('Warning: image was too large to display in format \"{}\"; '\n",
        "             'trying jpeg instead.').format(format)\n",
        "      return imshow(a, format='jpeg')\n",
        "    else:\n",
        "      raise\n",
        "  return disp\n",
        " \n",
        "def showarray(a, fmt='png'):\n",
        "    a = np.uint8(a)\n",
        "    f = StringIO()\n",
        "    PIL.Image.fromarray(a).save(f, fmt)\n",
        "    IPython.display.display(IPython.display.Image(data=f.getvalue()))\n",
        " \n",
        "        \n",
        "def clamp(x, minimum, maximum):\n",
        "    return max(minimum, min(x, maximum))\n",
        "    \n",
        "def drawLatent(image,latents,x,y,x2,y2, color=(255,0,0,100)):\n",
        "  buffer = PIL.Image.new('RGBA', image.size, (0,0,0,0))\n",
        "   \n",
        "  draw = ImageDraw.Draw(buffer)\n",
        "  cy = (y+y2)/2\n",
        "  draw.rectangle([x,y,x2,y2],fill=(255,255,255,180), outline=(0,0,0,180))\n",
        "  for i in range(len(latents)):\n",
        "    mx = x + (x2-x)*(float(i)/len(latents))\n",
        "    h = (y2-y)*latents[i]*0.1\n",
        "    h = clamp(h,cy-y2,y2-cy)\n",
        "    draw.line((mx,cy,mx,cy+h),fill=color)\n",
        "  return PIL.Image.alpha_composite(image,buffer)\n",
        "             \n",
        "  \n",
        "def createImageGrid(images, scale=0.25, rows=1):\n",
        "   w,h = images[0].size\n",
        "   w = int(w*scale)\n",
        "   h = int(h*scale)\n",
        "   height = rows*h\n",
        "   cols = ceil(len(images) / rows)\n",
        "   width = cols*w\n",
        "   canvas = PIL.Image.new('RGBA', (width,height), 'white')\n",
        "   for i,img in enumerate(images):\n",
        "     img = img.resize((w,h), PIL.Image.ANTIALIAS)\n",
        "     canvas.paste(img, (w*(i % cols), h*(i // cols))) \n",
        "   return canvas\n",
        " \n",
        "def convertZtoW(latent, truncation_psi, truncation_cutoff=9):\n",
        "  dlatent = Gs.components.mapping.run(latent, None) # [seed, layer, component]\n",
        "  dlatent_avg = Gs.get_var('dlatent_avg') # [component]\n",
        "  for i in range(truncation_cutoff):\n",
        "    dlatent[0][i] = (dlatent[0][i]-dlatent_avg)*truncation_psi + dlatent_avg\n",
        "    \n",
        "  return dlatent\n",
        " \n",
        "def interpolate(zs, steps):\n",
        "   out = []\n",
        "   for i in range(len(zs)-1):\n",
        "    for index in range(steps):\n",
        "     fraction = index/float(steps) \n",
        "     out.append(zs[i+1]*fraction + zs[i]*(1-fraction))\n",
        "   return out\n",
        " \n",
        "# Taken from https://github.com/alexanderkuk/log-progress\n",
        "def log_progress(sequence, every=1, size=None, name='Items'):\n",
        "    from ipywidgets import IntProgress, HTML, VBox\n",
        "    from IPython.display import display\n",
        " \n",
        "    is_iterator = False\n",
        "    if size is None:\n",
        "        try:\n",
        "            size = len(sequence)\n",
        "        except TypeError:\n",
        "            is_iterator = True\n",
        "    if size is not None:\n",
        "        if every is None:\n",
        "            if size <= 200:\n",
        "                every = 1\n",
        "            else:\n",
        "                every = int(size / 200)     # every 0.5%\n",
        "    else:\n",
        "        assert every is not None, 'sequence is iterator, set every'\n",
        " \n",
        "    if is_iterator:\n",
        "        progress = IntProgress(min=0, max=1, value=1)\n",
        "        progress.bar_style = 'info'\n",
        "    else:\n",
        "        progress = IntProgress(min=0, max=size, value=0)\n",
        "    label = HTML()\n",
        "    box = VBox(children=[label, progress])\n",
        "    display(box)\n",
        " \n",
        "    index = 0\n",
        "    try:\n",
        "        for index, record in enumerate(sequence, 1):\n",
        "            if index == 1 or index % every == 0:\n",
        "                if is_iterator:\n",
        "                    label.value = '{name}: {index} / ?'.format(\n",
        "                        name=name,\n",
        "                        index=index\n",
        "                    )\n",
        "                else:\n",
        "                    progress.value = index\n",
        "                    label.value = u'{name}: {index} / {size}'.format(\n",
        "                        name=name,\n",
        "                        index=index,\n",
        "                        size=size\n",
        "                    )\n",
        "            yield record\n",
        "    except:\n",
        "        progress.bar_style = 'danger'\n",
        "        raise\n",
        "    else:\n",
        "        progress.bar_style = 'success'\n",
        "        progress.value = index\n",
        "        label.value = \"{name}: {index}\".format(\n",
        "            name=name,\n",
        "            index=str(index or '?')\n",
        "        )\n",
        " \n",
        "def save_infer_images(images, z_latents, save_latents=True):\n",
        "    from tqdm import tqdm\n",
        "    \n",
        "    print('Total Images =',len(images))\n",
        "    for idx in tqdm(range(len(images))):\n",
        "        #print(idx)\n",
        "        img = images[idx]\n",
        "        # img = img.resize((240,240))\n",
        "        img.save(f\"{inference_results}{idx}_image.png\")\n",
        "\n",
        "    \n",
        "    if save_latents==True:\n",
        "        if not os.path.isdir(latent_results):\n",
        "            os.mkdir(latent_results)\n",
        "\n",
        "        for z_idx,z_lat in enumerate(z_latents):\n",
        "            np.save(f\"{latent_results}{z_idx}_latent.npy\", z_lat)\n",
        " \n",
        "def main(network_pkl,grid):\n",
        "    global Gs\n",
        "    global noise_vars\n",
        "    dnnlib.tflib.init_tf()\n",
        "    \n",
        "    \n",
        "\n",
        "    print('Loading networks from \"%s\"...' % network_pkl)\n",
        "    with dnnlib.util.open_url(network_pkl) as fp:\n",
        "        _G, _D, Gs = pickle.load(fp)\n",
        "        noise_vars = [var for name, var in Gs.components.synthesis.vars.items() if name.startswith('noise')]\n",
        "    if not os.path.isdir(inference_results):\n",
        "        os.mkdir(inference_results)\n",
        "    \n",
        "    seeds = np.random.randint((2**32 - 1), size=grid_height*grid_width)\n",
        "    if grid==1:\n",
        "        createImageGrid(generate_images_from_seeds(seeds, 1.4), 2.0 , grid_height).save(inference_results+'GAN_result_grid.png')\n",
        "        print('Grid Saved !!!')\n",
        "    else:  \n",
        "\n",
        "        zs = generate_zs_from_seeds(seeds)\n",
        "        dls = []\n",
        "        for z in zs:\n",
        "            dls.append(convertZtoW(z ,truncation_psi=trunc_idx))\n",
        "\n",
        "        gen_images = generate_images_in_w_space(dls, trunc_idx)\n",
        "        save_infer_images(gen_images, dls, True)\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    main(inference_ckpt, 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185,
          "referenced_widgets": [
            "5f7f907d6a034beba8bd6adfdbe25452",
            "31f4605bed1d49e793c18756c7de6ca3",
            "d8af0105b456417188f5e5a18025c61e",
            "9c9fd56551214232aa9516d4f84f11e0",
            "7cb7b3d052964988b0061a0307f1ba10",
            "a244df1ebbec4ac18e066128dcfc0b2b",
            "03dcda9d2733478eb8990b3cdd649c1a",
            "fcdab4163c9b4a92a4a529ea5e7df1ff"
          ]
        },
        "id": "u7WDFzGcsWyZ",
        "outputId": "84fba8dd-7ef7-49c9-fb08-ae697ef9263b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Loading networks from \"pretrained/pretrained_ada_ffhq_1024.pkl\"...\n",
            "Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n",
            "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f7f907d6a034beba8bd6adfdbe25452",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(HTML(value=''), IntProgress(value=1, bar_style='info', max=1)))"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Images = 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:09<00:00,  2.01it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "W0wyUfZ_scrJ"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}