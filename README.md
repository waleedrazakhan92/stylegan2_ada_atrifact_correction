# stylegan2_ada_atrifact_correction

Working with deep neural networks requires a lot of data to train models with reasonable accuracy. Sometimes this data is very hard to come by. So there arises a need for synthetic data. The quality of data is as important, if not more, as the amount of it. If we move in the image domain, you can see a lot of applications regarding human faces, like face detection and identification, fun apps like face aging and manipulation, virtual makeup, and there are many more. 

StyleGan2-ada is a popular architecture which can generate realistic looking human faces and can be used as a source of human face data. But sometimes the results are not perfect. Stylegan generates images from random seeds which range 0 to 232. These seeds are first converted into 512 dimensional vectors called the latent space and then these unique images are generated from this latent space. If we manipulate the latent space we can manipulate the semantics of the images like eye color, hair size, hair color and much more. Manipulating the latent space such that it doesnâ€™t affect more than one attribute requires a little engineering. First we need to identify which value, in latent space, affects which attribute in the image. For that we first generate a set of images, in this case 20 thousand, from stylegan and keep their latent vectors for manipulation. Then we manually separate out the latent vectors of acceptable images from the unacceptable ones which turn out to be approximately 1700. Then we train a simple classifier on that. Once the classifier is trained we can use its weights to manipulate the latent vector in the correct direction. Note that for custom images we need to find out the latent representation of the images(projection) first and then only we can manipulate it. Since the stylegan is trained on Flicker Faces HQ dataset which is aligned and cropped in the preprocessing phase, we also need to first align the images and then project them in the latent space.

# Correction Samples
![](<corrected_2.png>)
![](<corrected_3.png>)
